{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc4390de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import fitz\n",
    "from bs4 import BeautifulSoup\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "import uuid\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "upstage_api_key = os.getenv(\"UPSTAGE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93dea736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pdf(input_file, batch_size):\n",
    "    # Open input_pdf\n",
    "    input_pdf = fitz.open(input_file)\n",
    "    num_pages = len(input_pdf)\n",
    "    print(f\"Total number of pages: {num_pages}\")\n",
    " \n",
    "    # Split input_pdf\n",
    "    for start_page in range(0, num_pages, batch_size):\n",
    "        end_page = min(start_page + batch_size, num_pages) - 1\n",
    " \n",
    "        # Write output_pdf to file\n",
    "        input_file_basename = os.path.splitext(input_file)[0]\n",
    "        output_file = f\"{input_file_basename}_{start_page}_{end_page}.pdf\"\n",
    "        print(output_file)\n",
    "        with fitz.open() as output_pdf:\n",
    "            output_pdf.insert_pdf(input_pdf, from_page=start_page, to_page=end_page)\n",
    "            output_pdf.save(output_file)\n",
    " \n",
    "    # Close input_pdf\n",
    "    input_pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a0799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pages: 10\n",
      "lloydk_Q&A_0_0.pdf\n",
      "lloydk_Q&A_1_1.pdf\n",
      "lloydk_Q&A_2_2.pdf\n",
      "lloydk_Q&A_3_3.pdf\n",
      "lloydk_Q&A_4_4.pdf\n",
      "lloydk_Q&A_5_5.pdf\n",
      "lloydk_Q&A_6_6.pdf\n",
      "lloydk_Q&A_7_7.pdf\n",
      "lloydk_Q&A_8_8.pdf\n",
      "lloydk_Q&A_9_9.pdf\n"
     ]
    }
   ],
   "source": [
    "# Input arguments\n",
    "input_file = \"lloydk_Q&A.pdf\" # Replace with a file of your own\n",
    "batch_size = 1  # Maximum available value is 100\n",
    "split_pdf(input_file, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a47189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테이블을 구분하는 코드\n",
    "\n",
    "tables = []\n",
    "paragraphs = []\n",
    "\n",
    "for i in range(10):\n",
    "    filename = f\"lloydk_Q&A_{i}_{i}.pdf\"\n",
    "    url = \"https://api.upstage.ai/v1/document-digitization\"\n",
    "    headers = {\"Authorization\": f\"Bearer {upstage_api_key}\"}\n",
    "    files = {\"document\": open(filename, \"rb\")}\n",
    "    data = {\"ocr\": \"force\", \"base64_encoding\": \"['table']\", \"model\": \"document-parse\"}\n",
    "    response = requests.post(url, headers=headers, files=files, data=data)\n",
    "    for element in response.json()['elements']:\n",
    "        if element['category'] == 'table':\n",
    "            table_html = element['content'][\"html\"]\n",
    "            soup = BeautifulSoup(table_html, \"html.parser\")\n",
    "            # rows = []\n",
    "            for tr in soup.find_all(\"tr\"):\n",
    "                cells = [\n",
    "                    td.get_text(strip=True).replace(\"\\n\", \" \")\n",
    "                    for td in tr.find_all([\"td\", \"th\"])\n",
    "                ]\n",
    "                paragraphs.append(cells)\n",
    "            # for r in rows:\n",
    "            #     paragraphs.append(r)\n",
    "        else:\n",
    "            html_str = element['content']['html']\n",
    "            if html_str.startswith('\"') and html_str.endswith('\"'):\n",
    "                html_str = html_str[1:-1]\n",
    "            soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "            text = soup.get_text(\" \", strip=False)\n",
    "            paragraphs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f64028",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = []\n",
    "current_type = None   # 'text' 혹은 'table'\n",
    "current_items = []\n",
    "\n",
    "def item_type(item):\n",
    "    # 문자열이면 문장\n",
    "    if isinstance(item, str):\n",
    "        return \"text\"\n",
    "    # 리스트면 (여기서는) 테이블\n",
    "    if isinstance(item, list):\n",
    "        return \"table\"\n",
    "    return \"other\"\n",
    "\n",
    "for item in paragraphs:\n",
    "    t = item_type(item)\n",
    "\n",
    "    # text / table / other 타입이 바뀌면 이전 블록을 마무리\n",
    "    if t != current_type:\n",
    "        if current_items:\n",
    "            blocks.append({\n",
    "                \"type\": current_type,\n",
    "                \"items\": current_items\n",
    "            })\n",
    "        current_type = t\n",
    "        current_items = []\n",
    "\n",
    "    current_items.append(item)\n",
    "\n",
    "# 마지막 블록도 추가\n",
    "if current_items:\n",
    "    blocks.append({\n",
    "        \"type\": current_type,\n",
    "        \"items\": current_items\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f42891",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_embedding = []\n",
    "for i in range(len(blocks)):\n",
    "    texts = []\n",
    "    if blocks[i]['type'] == 'text':\n",
    "        texts.append(blocks[i]['items'])\n",
    "        text_for_embedding.append(texts[0])\n",
    "    else:\n",
    "        texts = []\n",
    "        texts.append(blocks[i-1]['items'][-1:]+blocks[i]['items'])\n",
    "        text_for_embedding.append(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a855a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_char_with_overlap(lines, max_chars=700, overlap_chars=50):\n",
    "    \"\"\"\n",
    "    lines: 이미 문장 단위로 나뉜 리스트 (list[str])\n",
    "    max_chars: 청크 하나의 최대 글자 수\n",
    "    overlap_chars: 다음 청크로 넘길 최소 글자 수 (겹치는 분량)\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current = []\n",
    "    cur_len = 0\n",
    "\n",
    "    for raw in lines:\n",
    "        line = raw.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        line_len = len(line)\n",
    "\n",
    "        # 이 줄을 더하면 max_chars를 넘는 경우 → 지금까지 걸 하나의 청크로 확정\n",
    "        if current and (cur_len + line_len > max_chars):\n",
    "            # 현재 청크 저장\n",
    "            chunks.append(\"\\n\".join(current))\n",
    "\n",
    "            # 🔁 오버랩 부분 만들기: 뒤에서부터 overlap_chars 이상이 될 때까지 가져오기\n",
    "            overlap = []\n",
    "            overlap_len = 0\n",
    "            for s in reversed(current):\n",
    "                if overlap_len + len(s) > overlap_chars and overlap:\n",
    "                    break\n",
    "                overlap.append(s)\n",
    "                overlap_len += len(s)\n",
    "            overlap = list(reversed(overlap))\n",
    "\n",
    "            current = overlap[:]          # 새 청크는 오버랩으로 시작\n",
    "            cur_len = sum(len(s) for s in current)\n",
    "\n",
    "        # 현재 청크에 이 줄 추가\n",
    "        current.append(line)\n",
    "        cur_len += line_len\n",
    "\n",
    "    # 마지막 청크 처리\n",
    "    if current:\n",
    "        chunks.append(\"\\n\".join(current))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b94e484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_for_chunks = []\n",
    "for chunks in text_for_embedding:\n",
    "    if type(chunks[1]) == list:\n",
    "        list_for_chunks.append(chunks)\n",
    "        continue\n",
    "    else:\n",
    "        num_chunks = chunk_by_char_with_overlap(chunks)\n",
    "        for num in num_chunks:\n",
    "            list_for_chunks.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4496e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY가 .env에 없어요 ㅠㅠ\")\n",
    "\n",
    "client_oa = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Qdrant 클라이언트 (로컬)\n",
    "client_qd = QdrantClient(\n",
    "    url=\"http://localhost:6333\",  # 또는 host=\"localhost\", port=6333\n",
    ")\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-3-small\"\n",
    "EMBED_DIM = 1536  # text-embedding-3-small의 차원 수\n",
    "COLLECTION_NAME = \"lloydk_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b963c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking collection existence...\n",
      "→ Exists? True\n",
      "⚙️ Collection already exists: lloydk_docs\n"
     ]
    }
   ],
   "source": [
    "def ensure_collection():\n",
    "    print(\"🔍 Checking collection existence...\")\n",
    "    exists = client_qd.collection_exists(collection_name=COLLECTION_NAME)\n",
    "    print(f\"→ Exists? {exists}\")\n",
    "\n",
    "    if not exists:\n",
    "        client_qd.create_collection(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            vectors_config=VectorParams(size=EMBED_DIM, distance=Distance.COSINE),\n",
    "        )\n",
    "        print(f\"✅ Created collection: {COLLECTION_NAME}\")\n",
    "    else:\n",
    "        print(f\"⚙️ Collection already exists: {COLLECTION_NAME}\")\n",
    "        \n",
    "ensure_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3a4f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_batch(texts):\n",
    "    \"\"\"\n",
    "    texts: list[str]\n",
    "    return: list[list[float]] (임베딩 벡터들)\n",
    "    \"\"\"\n",
    "    # 빈 문자열 제거 + 전처리\n",
    "    cleaned = []\n",
    "    idx_map = []\n",
    "\n",
    "    for i, t in enumerate(texts):\n",
    "        if not isinstance(t, str):\n",
    "            t = str(t)\n",
    "        t = t.strip()\n",
    "        if not t:\n",
    "            continue\n",
    "        cleaned.append(t)\n",
    "        idx_map.append(i)\n",
    "\n",
    "    if not cleaned:\n",
    "        return [], []\n",
    "\n",
    "    resp = client_oa.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=cleaned,\n",
    "    )\n",
    "\n",
    "    vectors = [d.embedding for d in resp.data]\n",
    "    return vectors, cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14aa25a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_for_chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mlist_for_chunks\u001b[49m), BATCH_SIZE):\n\u001b[0;32m      3\u001b[0m     batch \u001b[38;5;241m=\u001b[39m list_for_chunks[i:i\u001b[38;5;241m+\u001b[39mBATCH_SIZE]\n\u001b[0;32m      4\u001b[0m     vectors, cleaned \u001b[38;5;241m=\u001b[39m embed_batch(batch)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'list_for_chunks' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "for i in range(0, len(list_for_chunks), BATCH_SIZE):\n",
    "    batch = list_for_chunks[i:i+BATCH_SIZE]\n",
    "    vectors, cleaned = embed_batch(batch)\n",
    "\n",
    "    points = [\n",
    "        PointStruct(\n",
    "            id=str(uuid.uuid4()),\n",
    "            vector=vec,\n",
    "            payload={\"text\": text},\n",
    "        )\n",
    "        for text, vec in zip(cleaned, vectors)\n",
    "    ]\n",
    "\n",
    "    client_qd.upsert(collection_name=\"lloydk_docs\", points=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbad25cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.564\n",
      "text: RAG 워크플로에서 사용자의 프롬프트(질문)는 먼저 검색 단계로 전달된다.\n",
      "즉, 입력된 질문은 임베딩 모델을 통해 벡터로 변환되어 벡터 DB에 쿼리된다.\n",
      "RAG 파이프라인은 \"사용자 쿼리를 임베딩하여 인덱싱된 문서에 유사도 검색을 수행하고, 가장 유사 한 문서를 추출\"하는 방식으로 동작한다.\n",
      "이후 검색된 문서들과 원래 질문이 함께 LLM에 주어져 답변을 생성하게 된다.\n",
      "11. AI 에이전트란 무엇인가? 계층구조 적용의 장점은?\n",
      "AI 에이전트는 환경과 상호작용하면서 주어진 목표를 달성하기 위해 필요한 행동을 스스로 계획하 고 수행하는 자율 지능 시스템이다.\n",
      "예를 들어 고객문의 상담을 자동으로 처리하며 추가 정보를 탐색하는 챗봇이 이에 해당한다.\n",
      "계층형 에이전트(상위/하위 계층)를 적용하면 상위 에이전트가 전체 작업을 작은 과제로 분해하여 하위 에이전트에게 할당할 수 있다.\n",
      "이러한 구조를 활용하면 각 하위 에이전트가 독립적이고 전문화된 역할(예: 검색, 분석, 행동 등)을 수행할 수 있어 신뢰성과 재사용성이 높아진다.\n",
      "12. 고객, 직원, 데이터, 시큐리티 에이전트의 역할은?\n",
      "· 고객 에이전트: 고객의 문의에 응대하고 요구에 맞는 정보를 제공한다.\n",
      "。 예를 들어 Microsoft는 \"제품 카탈로그 정보를 모두 학습해 고객 질문에 상세히 답변\"하는 에이 전트를 언급했다.\n",
      "· 직원 에이전트: 조직 내부 직원을 지원하는 역할로,\n",
      "\n",
      "score: 0.533\n",
      "text: · 직원 에이전트: 조직 내부 직원을 지원하는 역할로,\n",
      "。 예를 들면 영업사원의 목표 달성을 돕기 위해 \"영업 리드 생성\" 같은 업무를 자동화하는 에이전 트가 해당한다.\n",
      "· 데이터 에이전트: 회사의 내부 데이터를 수집·전처리·분석하여 RAG 등에 활용 가능한 지식을 제 공한다.\n",
      "。 예를 들어 사내 문서나 DB를 정기적으로 인덱싱해 임베딩하고, 엔티티 추출·정합성 검증 등을 수행한다.\n",
      "· 시큐리티 에이전트: AI 시스템 전체의 보안·권한 관리를 담당한다.\n",
      "。 사용자 인증, 문서 접근 제어, 활동 로그 모니터링 등을 통해 시스템 안전성을 강화한다.\n",
      "13. Agentic RAG란 무엇인가? LLM과 유연하게 연계되는 방식은?\n",
      "Agentic RAG는 RAG 파이프라인에 AI 에이전트를 도입한 개념으로, 에이전트가 여러 검색/도구를 유연히 사용하도록 확장한 방식이다.\n",
      "즉, 단순히 벡터 검색만 하는 것이 아니라 LLM 기반 에이전트가 웹 검색·계산기·API 호출 등 여러 도 구를 필요에 따라 활용해 정보를 조회한다.\n",
      "에이전트는 쿼리 내용을 분석해 최적의 검색 수단을 선택하고, 필요 시 여러 단계를 거쳐 정보를 보 충한다.\n",
      "이렇게 하면 한 번에 하나의 지식원만 참조하는 기존 RAG의 한계를 넘어 보다 정교하고 유연한 정 보 검색·통합이 가능하다.\n",
      "14. AI 컨설팅은 누가 수행하며, 어떤 내용이 포함되는가?\n",
      "→ 이부분은 별도 설명 필요\n",
      "\n",
      "score: 0.413\n",
      "text: 3. 권한 관리는 어떤 식으로 이루어지는가? (관리자, 사용자)\n",
      "권한 관리는 관리자(Admin)와 일반 사용자(User)에게 서로 다른 접근 범위를 부여하는 방식으로 구 현된다.\n",
      "예를 들어 RAG 시스템에서는 문서 색인 시 각 문서에 접근 가능한 사용자나 역할을 지정하고, 사용 자가 쿼리할 때 현재 사용자에게 허용된 문서만 검색되도록 필터링한다.\n",
      "이를 통해 관리자는 전체 문서에 대한 조회 권한을 가질 수 있고, 일반 사용자는 미리 정의된 역할 범 위 내의 문서만 이용하도록 제어할 수 있다.\n",
      "DO 솔루션의 시큐리티 에이전트(DO-SA) 모듈은 이같은 인증/권한 설정과 실시간 모니터링을 제공 하여 보안 정책을 관리한다.\n",
      "RBAC (Role-Based Access Control)\n",
      "RBAC는 권한을 직접 사용자에게 주는 방식이 아닌, 역할(Role)을 통해 간접적으로 부여하는 방식입 니다.\n",
      "즉,\n",
      "· 권한(Permissions) → 기능 수행 권한 (예: 읽기, 쓰기) · 역할(Role) → 여러 권한의 묶음 (예: 관리자, 편집자, 뷰어) · 사용자(User) → 하나 이상의 역할을 가짐\n",
      "이렇게 권한 → 역할 → 사용자 순서로 계층이 구성되어 관리가 단순하고, 확장성이 좋습니다.\n",
      "4. 오케스트레이션 프레임워크가 무엇인가?\n",
      "오케스트레이션 프레임워크는 LLM, 검색기, 도구(API) 등 AI 애플리케이션의 구성 요소들을 연계하 고 제어해주는 통합 도구다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"AI 에이전트별로 역할이 있어?\"\n",
    "q_emb, _ = embed_batch([query])\n",
    "\n",
    "results = client_qd.query_points(\n",
    "    collection_name=\"lloydk_docs\",\n",
    "    query=q_emb[0],   # query_vector → query\n",
    "    limit=3,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "for r in results.points:\n",
    "    print(f\"score: {r.score:.3f}\")\n",
    "    print(f\"text: {r.payload['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "907f7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chat():\n",
    "    print(\"RAG 챗봇입니다. 'exit' 입력 시 종료.\\n\")\n",
    "    while True:\n",
    "        q = input(\"👤 질문: \").strip()\n",
    "        if not q:\n",
    "            continue\n",
    "        if q.lower() in [\"exit\", \"quit\", \"q\"]:\n",
    "            print(\"bye~\")\n",
    "            break\n",
    "\n",
    "        # 1️⃣ 쿼리 임베딩\n",
    "        q_emb, _ = embed_batch([q])\n",
    "\n",
    "        # 2️⃣ Qdrant에서 검색\n",
    "        results = client_qd.query_points(\n",
    "            collection_name=\"lloydk_docs\",\n",
    "            query=q_emb[0],\n",
    "            limit=5,\n",
    "            with_payload=True\n",
    "        )\n",
    "\n",
    "        # 3️⃣ 검색된 문서 모으기\n",
    "        contexts = [r.payload[\"text\"] for r in results.points if \"text\" in r.payload]\n",
    "        if not contexts:\n",
    "            print(\"🤖 관련 문서를 찾지 못했어요 ㅠㅠ\\n\")\n",
    "            continue\n",
    "\n",
    "        # 4️⃣ 답변 생성\n",
    "        context_text = \"\\n\\n\".join(contexts)\n",
    "        system_prompt = (\n",
    "            \"너는 DO 솔루션 관련 기술 문서를 바탕으로 답변하는 어시스턴트야.\\n\"\n",
    "            \"반드시 아래 제공된 문맥 내에서만 답변해. 모르면 모른다고 말해.\\n\"\n",
    "            \"table의 경우, [[열1, 열2], [열1에 대한 아이템, 열2에 대한 아이템]...] 이런 식으로 되어있으니 반드시 끝까지 다 보고 답변해야 해.\"\n",
    "        )\n",
    "        user_prompt = (\n",
    "            f\"[질문]\\n{q}\\n\\n[관련 문서]\\n{context_text}\\n\\n\"\n",
    "            \"위 내용을 기반으로 한국어로 자연스럽게 답변해줘.\"\n",
    "        )\n",
    "\n",
    "        resp = client_oa.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "        )\n",
    "\n",
    "        print(\"\\n🤖 답변:\\n\", resp.choices[0].message.content, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bef5787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 챗봇입니다. 'exit' 입력 시 종료.\n",
      "\n",
      "\n",
      "🤖 답변:\n",
      " 현재 컨텍스트 윈도우가 가장 긴 언어 모델은 \"GPT-4o\"로, 2M의 컨텍스트 윈도우를 가지고 있습니다. 이 모델은 텍스트와 이미지를 동시에 처리할 수 있는 복합 AI 서비스에 적합한 최고 성능의 모델로 알려져 있습니다. \n",
      "\n",
      "bye~\n"
     ]
    }
   ],
   "source": [
    "rag_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88943a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
